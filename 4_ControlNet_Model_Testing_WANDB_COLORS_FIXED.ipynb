{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJl1Y4IQFogf"
      },
      "source": [
        "# ControlNet Floorplan Generator - Testing Notebook\n",
        "\n",
        "**Test your trained model with upload/drawing before deploying!**\n",
        "\n",
        "## What This Does:\n",
        "- ‚úÖ Load your trained ControlNet model\n",
        "- ‚úÖ Test with dataset samples (check overfitting)\n",
        "- ‚úÖ Upload your own segmentation masks\n",
        "- ‚úÖ Draw custom layouts interactively\n",
        "- ‚úÖ Generate variations & explore parameters\n",
        "- ‚úÖ Save results for your report\n",
        "\n",
        "## Setup Instructions:\n",
        "1. **Runtime ‚Üí Change runtime type ‚Üí T4 GPU**\n",
        "2. Run cells in order from top to bottom\n",
        "3. Wait for model loading (~2-3 minutes)\n",
        "4. Start testing!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSO7cULcFogg"
      },
      "source": [
        "## Step 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJA_WDtSFogg"
      },
      "outputs": [],
      "source": [
        "# === INSTALLATION - FIXED FOR COMPATIBILITY ===\n",
        "# This fixes the 'cached_download' import error\n",
        "\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\\n\")\n",
        "\n",
        "# Clean install to avoid conflicts\n",
        "print(\"Cleaning old packages...\")\n",
        "!pip uninstall -y diffusers transformers accelerate huggingface_hub -q\n",
        "\n",
        "# Install latest compatible versions\n",
        "print(\"Installing compatible packages...\")\n",
        "!pip install -q diffusers>=0.27.0\n",
        "!pip install -q transformers>=4.40.0\n",
        "!pip install -q accelerate>=0.27.0\n",
        "!pip install -q huggingface_hub>=0.20.0\n",
        "!pip install -q gradio>=4.20.0\n",
        "!pip install -q datasets\n",
        "\n",
        "# Verify installation\n",
        "print(\"\\nVerifying installation...\")\n",
        "import torch\n",
        "try:\n",
        "    from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
        "    from transformers import __version__ as trans_ver\n",
        "    from diffusers import __version__ as diff_ver\n",
        "    print(f\"Diffusers: {diff_ver}\")\n",
        "    print(f\"Transformers: {trans_ver}\")\n",
        "    print(f\"PyTorch: {torch.__version__}\")\n",
        "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(\"\\nInstallation complete! You can proceed.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"\\nIf you see an error, click Runtime ‚Üí Restart runtime, then re-run this cell.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJzCJy4rFogh"
      },
      "source": [
        "## Step 2: Load Your Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlgIA_neFogh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "import gradio as gr\n",
        "import random\n",
        "\n",
        "print(\"Loading your trained ControlNet model...\")\n",
        "print(\"This takes 2-3 minutes on first load\")\n",
        "\n",
        "# Load your trained ControlNet\n",
        "controlnet = ControlNetModel.from_pretrained(\n",
        "    \"aqhareus/controlnet-floorplan-final\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# Load Stable Diffusion pipeline\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "    \"stable-diffusion-v1-5/stable-diffusion-v1-5\",\n",
        "    controlnet=controlnet,\n",
        "    torch_dtype=torch.float16,\n",
        "    safety_checker=None\n",
        ")\n",
        "\n",
        "# Move to GPU and optimize memory\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "pipe = pipe.to(device)\n",
        "pipe.enable_model_cpu_offload()\n",
        "pipe.enable_attention_slicing()\n",
        "\n",
        "print(f\"\\nModel loaded successfully on {device}!\")\n",
        "print(f\"Memory optimizations enabled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0KGnTxhFogh"
      },
      "source": [
        "## Step 3: Define Room Colors & Generation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StkseOgQFogh"
      },
      "outputs": [],
      "source": [
        "# Room color palette (matching your dataset)\n",
        "# Room color palette - CORRECTED TO MATCH ACTUAL DATASET\n",
        "# These are the exact RGB values your model was trained on!\n",
        "# Room color palette - UPDATED from dataset analysis\n",
        "ROOM_COLORS = {\n",
        "    \"Living Room\": (154, 255, 0),      # Lime/Yellow-Green\n",
        "    \"Bedroom\": (254, 154, 0),          # Orange\n",
        "    \"Kitchen\": (154, 255, 0),          # Lime/Yellow-Green (same as Living Room)\n",
        "    \"Bathroom\": (0, 155, 255),         # Cyan/Light Blue\n",
        "    \"Closet\": (99, 80, 71),            # Brown/Gray\n",
        "    \"Corridor\": (49, 99, 155),         # Dark Blue\n",
        "    \"Toilet\": (0, 0, 0),               # Black\n",
        "}\n",
        "\n",
        "print(\"Room Color Palette:\")\n",
        "for room, color in ROOM_COLORS.items():\n",
        "    print(f\"   {room:15s} ‚Üí RGB{color}\")\n",
        "\n",
        "def generate_floorplan(\n",
        "    segmentation_mask,\n",
        "    prompt=\"a clean architectural floorplan with walls and rooms\",\n",
        "    num_inference_steps=20,\n",
        "    controlnet_conditioning_scale=1.0,\n",
        "    seed=42,\n",
        "    show_comparison=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate a floorplan from a segmentation mask.\n",
        "\n",
        "    Args:\n",
        "        segmentation_mask: PIL Image or numpy array (RGB)\n",
        "        prompt: Text description\n",
        "        num_inference_steps: Quality (10-50, higher=better/slower)\n",
        "        controlnet_conditioning_scale: Layout strictness (0.5-2.0)\n",
        "        seed: Random seed for reproducibility\n",
        "        show_comparison: Display input vs output\n",
        "\n",
        "    Returns:\n",
        "        Generated PIL Image\n",
        "    \"\"\"\n",
        "    # Prepare image\n",
        "    if isinstance(segmentation_mask, np.ndarray):\n",
        "        segmentation_mask = Image.fromarray(segmentation_mask)\n",
        "\n",
        "    segmentation_mask = segmentation_mask.convert(\"RGB\").resize((512, 512), Image.LANCZOS)\n",
        "\n",
        "    # Generate\n",
        "    generator = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "    output = pipe(\n",
        "        prompt=prompt,\n",
        "        image=segmentation_mask,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        controlnet_conditioning_scale=controlnet_conditioning_scale,\n",
        "        generator=generator,\n",
        "        guidance_scale=7.5\n",
        "    )\n",
        "\n",
        "    generated = output.images[0]\n",
        "\n",
        "    # Display comparison\n",
        "    if show_comparison:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        axes[0].imshow(segmentation_mask)\n",
        "        axes[0].set_title(\"Input Segmentation\", fontsize=14, fontweight='bold')\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        axes[1].imshow(generated)\n",
        "        axes[1].set_title(\"Generated Floorplan\", fontsize=14, fontweight='bold')\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return generated\n",
        "\n",
        "print(\"\\nGeneration function ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3l2meglFogh"
      },
      "source": [
        "## Step 4: Test with Dataset Samples (Overfitting Check)\n",
        "\n",
        "**This tests if your model is overfitting by comparing:**\n",
        "- Input segmentation\n",
        "- Generated floorplan (your model)\n",
        "- Ground truth (training data)\n",
        "\n",
        "**What to look for:**\n",
        "- ‚úÖ Generated matches input layout structure\n",
        "- ‚úÖ Generated is NOT identical to ground truth (overfitting sign)\n",
        "- ‚úÖ Generated has realistic architectural details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwNZWoeWFogh"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "print(\"Loading test samples from dataset...\")\n",
        "dataset = load_dataset(\"Qistinasofea/floorplan-aligned-strict\", split=\"train\")\n",
        "\n",
        "# Test 3 random samples\n",
        "test_indices = random.sample(range(len(dataset)), 3)\n",
        "print(f\"Testing samples: {test_indices}\\n\")\n",
        "\n",
        "for i, idx in enumerate(test_indices):\n",
        "    sample = dataset[idx]\n",
        "\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Sample {i+1}/3 (Dataset index: {idx})\")\n",
        "    print(f\"Caption: {sample['captions']}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Generate\n",
        "    generated = generate_floorplan(\n",
        "        segmentation_mask=sample['colors'],\n",
        "        prompt=sample['captions'],\n",
        "        seed=42,\n",
        "        show_comparison=False\n",
        "    )\n",
        "\n",
        "    # Display: Input ‚Üí Generated ‚Üí Ground Truth\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    axes[0].imshow(sample['colors'])\n",
        "    axes[0].set_title(\"Input Segmentation\", fontsize=12, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(generated)\n",
        "    axes[1].set_title(\"Generated (Your Model)\", fontsize=12, fontweight='bold')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    axes[2].imshow(sample['plans'])\n",
        "    axes[2].set_title(\"Ground Truth\", fontsize=12, fontweight='bold')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.suptitle(f\"Dataset Sample {idx} - Overfitting Check\", fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nEvaluation Questions:\")\n",
        "    print(\" Does generated match input layout?\")\n",
        "    print(\" Is generated TOO similar to ground truth? (overfitting)\")\n",
        "    print(\" Are walls/rooms in correct positions?\\n\")\n",
        "\n",
        "print(\"\\n‚úÖ Dataset testing complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhCF5UMBFogi"
      },
      "source": [
        "## Step 5: Create Custom Layouts Programmatically\n",
        "\n",
        "Test your model on layouts it has NEVER seen before!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJExf3zcFogi"
      },
      "outputs": [],
      "source": [
        "def create_simple_layout(rooms_config, size=512):\n",
        "    \"\"\"\n",
        "    Create segmentation mask with ABSOLUTELY NO BORDERS.\n",
        "\n",
        "    Uses numpy array manipulation for pixel-perfect control.\n",
        "    PIL's draw.rectangle() has anti-aliasing artifacts - this doesn't!\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    # Create black background as numpy array\n",
        "    img_array = np.zeros((size, size, 3), dtype=np.uint8)\n",
        "\n",
        "    # Fill rooms by directly setting pixel values (NO BORDERS!)\n",
        "    for room_name, x, y, w, h in rooms_config:\n",
        "        color = ROOM_COLORS.get(room_name, (128, 128, 128))\n",
        "\n",
        "        # Direct pixel assignment - perfect fills, zero borders\n",
        "        img_array[y:y+h, x:x+w] = color\n",
        "\n",
        "    # Convert to PIL Image\n",
        "    return Image.fromarray(img_array, 'RGB')\n",
        "\n",
        "\n",
        "# Test Layout 1: Simple 2-Bedroom Apartment\n",
        "print(\"Test 1: Simple 2-Bedroom Apartment (PERFECT - No Borders)\")\n",
        "layout1 = create_simple_layout([\n",
        "    (\"Living Room\", 0, 0, 256, 256),      # Top-left\n",
        "    (\"Bedroom\", 256, 0, 256, 256),        # Top-right (starts at 256!)\n",
        "    (\"Living Room\", 0, 256, 128, 256),    # Bottom-left\n",
        "    (\"Bathroom\", 128, 256, 128, 256),     # Bottom-middle (starts at 128!)\n",
        "    (\"Bedroom\", 256, 256, 256, 256)       # Bottom-right (starts at 256!)\n",
        "])\n",
        "generated1 = generate_floorplan(layout1, seed=457)\n",
        "\n",
        "# Test Layout 2: Studio Apartment\n",
        "print(\"\\nTest 2: Studio Apartment\")\n",
        "layout2 = create_simple_layout([\n",
        "    (\"Living Room\", 0, 0, 512, 256),      # Full width top\n",
        "    (\"Corridor\", 0, 256, 256, 256),        # Left half\n",
        "    (\"Bathroom\", 256, 256, 256, 256)      # Right half (starts at 256!)\n",
        "])\n",
        "generated2 = generate_floorplan(layout2, seed=412)\n",
        "\n",
        "# Test Layout 3: Complex Multi-Room House\n",
        "print(\"\\nTest 3: Complex Multi-Room House\")\n",
        "layout3 = create_simple_layout([\n",
        "    # Row 1: Living Room (230px) + Kitchen (282px) = 512px ‚úì\n",
        "    (\"Living Room\", 0, 0, 230, 170),\n",
        "    (\"Kitchen\", 230, 0, 282, 170),\n",
        "\n",
        "    # Row 2: Corridor (20px) + Kitchen (210px) + Bedroom (282px) = 512px ‚úì\n",
        "    (\"Corridor\", 0, 170, 20, 170),\n",
        "    (\"Kitchen\", 20, 170, 210, 170),\n",
        "    (\"Bedroom\", 230, 170, 282, 170),\n",
        "\n",
        "    # Row 3: Bedroom (140px) + Toilet (70px) + Bedroom (160px) + Bathroom (142px) = 512px ‚úì\n",
        "    (\"Bedroom\", 0, 340, 140, 172),\n",
        "    (\"Toilet\", 140, 340, 70, 172),\n",
        "    (\"Bedroom\", 210, 340, 160, 172),\n",
        "    (\"Bathroom\", 370, 340, 142, 172)\n",
        "])\n",
        "generated3 = generate_floorplan(layout3, seed=212)\n",
        "\n",
        "print(\"\\n‚úÖ Custom layouts tested - ZERO borders!\")\n",
        "print(\"‚úÖ Using numpy for pixel-perfect control\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s44kSocFogi"
      },
      "source": [
        "## Step 6: Test Diversity (Multiple Seeds)\n",
        "\n",
        "**Check if your model generates diverse outputs or just memorized patterns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gD4VKrrFogi"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If you are in Colab / notebook and not logged in yet:\n",
        "# wandb.login()\n",
        "\n",
        "# ---- W&B init ----\n",
        "wandb.init(\n",
        "    project=\"AI54-Floorplan\",      # change\n",
        "    name=\"diversity_test_seeds_layout_latest\", # change\n",
        "    config={\n",
        "        \"layout\": \"layout2\",\n",
        "        \"seeds\": [42, 123, 456, 789],\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Generating 4 variations with different seeds...\\n\")\n",
        "\n",
        "test_layout = layout2  # Use studio apartment\n",
        "seeds = [42, 123, 456, 789]\n",
        "\n",
        "# Log the input segmentation once\n",
        "wandb.log({\"input_segmentation\": wandb.Image(test_layout, caption=\"Input Segmentation\")})\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Show input\n",
        "axes[0].imshow(test_layout)\n",
        "axes[0].set_title(\"Input Segmentation\", fontsize=12, fontweight=\"bold\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "# Generate variations + log to W&B\n",
        "for i, seed in enumerate(seeds):\n",
        "    generated = generate_floorplan(\n",
        "        segmentation_mask=test_layout,\n",
        "        seed=seed,\n",
        "        show_comparison=False\n",
        "    )\n",
        "\n",
        "    # Show in the grid\n",
        "    axes[i + 1].imshow(generated)\n",
        "    axes[i + 1].set_title(f\"Seed={seed}\", fontsize=12, fontweight=\"bold\")\n",
        "    axes[i + 1].axis(\"off\")\n",
        "\n",
        "    # Log each generated image to W&B\n",
        "    wandb.log({\n",
        "        \"seed\": seed,  # useful for filtering\n",
        "        f\"generated/seed_{seed}\": wandb.Image(generated, caption=f\"Generated (seed={seed})\")\n",
        "    })\n",
        "\n",
        "    # (Optional) Log side-by-side comparison (input + output) as a single image\n",
        "    panel_fig, panel_ax = plt.subplots(1, 2, figsize=(8, 4))\n",
        "    panel_ax[0].imshow(test_layout)\n",
        "    panel_ax[0].set_title(\"Input\")\n",
        "    panel_ax[0].axis(\"off\")\n",
        "    panel_ax[1].imshow(generated)\n",
        "    panel_ax[1].set_title(f\"Output (seed={seed})\")\n",
        "    panel_ax[1].axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    wandb.log({f\"comparison/seed_{seed}\": wandb.Image(panel_fig)})\n",
        "    plt.close(panel_fig)\n",
        "\n",
        "# Hide last subplot\n",
        "axes[5].axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"Diversity Test: Same Input, Different Seeds\", fontsize=14, fontweight=\"bold\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nEvaluation:\")\n",
        "print(\" Good: Outputs show variation (different details, styles)\")\n",
        "print(\" Bad: All outputs nearly identical (overfitting sign)\")\n",
        "\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgEKbj-CFogi"
      },
      "source": [
        "## Step 7: Explore Conditioning Scale\n",
        "\n",
        "**Test how strictly the model follows your input layout**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP7Oh9LaFogi"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If not logged in yet:\n",
        "# wandb.login()\n",
        "\n",
        "# ---- W&B init ----\n",
        "wandb.init(\n",
        "    project=\"AI54-Floorplan\",          # change if needed\n",
        "    name=\"conditioning_scale_test_layout2\",  # change if needed\n",
        "    config={\n",
        "        \"layout\": \"layout2\",\n",
        "        \"conditioning_scales\": [0.5, 0.75, 1.0, 1.5, 2.0],\n",
        "        \"seed\": 42\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Testing conditioning scale (layout strictness)...\\n\")\n",
        "\n",
        "scales = [0.5, 0.75, 1.0, 1.5, 2.0]\n",
        "test_layout = layout2\n",
        "\n",
        "# Log input once\n",
        "wandb.log({\n",
        "    \"input_segmentation\": wandb.Image(\n",
        "        test_layout, caption=\"Input Segmentation\"\n",
        "    )\n",
        "})\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Show input\n",
        "axes[0].imshow(test_layout)\n",
        "axes[0].set_title(\"Input Segmentation\", fontsize=12, fontweight=\"bold\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "# Test different conditioning scales\n",
        "for i, scale in enumerate(scales):\n",
        "    generated = generate_floorplan(\n",
        "        segmentation_mask=test_layout,\n",
        "        controlnet_conditioning_scale=scale,\n",
        "        seed=42,\n",
        "        show_comparison=False\n",
        "    )\n",
        "\n",
        "    # Display in grid\n",
        "    axes[i + 1].imshow(generated)\n",
        "    axes[i + 1].set_title(f\"Scale={scale}\", fontsize=12, fontweight=\"bold\")\n",
        "    axes[i + 1].axis(\"off\")\n",
        "\n",
        "    # Log generated image\n",
        "    wandb.log({\n",
        "        \"conditioning_scale\": scale,\n",
        "        f\"generated/scale_{scale}\": wandb.Image(\n",
        "            generated, caption=f\"Scale={scale}\"\n",
        "        )\n",
        "    })\n",
        "\n",
        "    # Optional: log input vs output comparison\n",
        "    panel_fig, panel_ax = plt.subplots(1, 2, figsize=(8, 4))\n",
        "    panel_ax[0].imshow(test_layout)\n",
        "    panel_ax[0].set_title(\"Input\")\n",
        "    panel_ax[0].axis(\"off\")\n",
        "    panel_ax[1].imshow(generated)\n",
        "    panel_ax[1].set_title(f\"Output (scale={scale})\")\n",
        "    panel_ax[1].axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    wandb.log({\n",
        "        f\"comparison/scale_{scale}\": wandb.Image(panel_fig)\n",
        "    })\n",
        "    plt.close(panel_fig)\n",
        "\n",
        "# Hide unused subplot\n",
        "axes[5].axis(\"off\")\n",
        "\n",
        "plt.suptitle(\n",
        "    \"Conditioning Scale Test: Layout Adherence\",\n",
        "    fontsize=14,\n",
        "    fontweight=\"bold\"\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nExpected Behavior:\")\n",
        "print(\"   ‚Ä¢ Scale 0.5: More creative freedom, looser layout\")\n",
        "print(\"   ‚Ä¢ Scale 1.0: Balanced (default)\")\n",
        "print(\"   ‚Ä¢ Scale 2.0: Stricter layout adherence\")\n",
        "\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPvRgsNjFogi"
      },
      "source": [
        "## Step 8: Interactive Drawing Interface (GRADIO)\n",
        "\n",
        "**Upload your own images OR draw layouts interactively!**\n",
        "\n",
        "This launches a web interface where you can:\n",
        "- Draw colored room layouts with a brush\n",
        "- Upload your own segmentation mask images\n",
        "- Adjust generation parameters\n",
        "- Get instant results\n",
        "\n",
        "**The interface will provide a public URL you can access on your phone!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "8g1LoTx_Fogi",
        "outputId": "57d111dc-4ce5-4ce8-ef42-03cd21bcf5d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://1fd6a47e1f32a95dd6.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1fd6a47e1f32a95dd6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ========================================================================\n",
        "# IMMEDIATE FIX - Copy and Run This in a New Cell Right Now\n",
        "# ========================================================================\n",
        "# This fixes the \"controlnet_conditioning_scale must be type float\" error\n",
        "# Just copy this entire block and run it in your current Colab session\n",
        "\n",
        "def gradio_generate(image_dict, prompt, steps, scale, seed):\n",
        "    \"\"\"Fixed Gradio wrapper with proper type conversion.\"\"\"\n",
        "    if image_dict is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Extract image\n",
        "        if isinstance(image_dict, dict) and 'composite' in image_dict:\n",
        "            img = image_dict['composite']\n",
        "        else:\n",
        "            img = image_dict\n",
        "\n",
        "        # FIX: Convert parameters to correct types\n",
        "        steps = int(steps)\n",
        "        scale = float(scale)    # THIS IS THE CRITICAL FIX!\n",
        "        seed = int(seed)\n",
        "\n",
        "        # Generate\n",
        "        result = generate_floorplan(\n",
        "            segmentation_mask=img,\n",
        "            prompt=str(prompt),\n",
        "            num_inference_steps=steps,\n",
        "            controlnet_conditioning_scale=scale,\n",
        "            seed=seed,\n",
        "            show_comparison=False\n",
        "        )\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# Now re-launch the Gradio interface with the fixed function\n",
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks(title=\"ControlNet Floorplan Tester\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ControlNet Floorplan Generator - Interactive Testing (FIXED)\n",
        "\n",
        "    **The type error has been fixed! Draw or upload your layouts.**\n",
        "\n",
        "    1. **Draw**: Use colored brush to draw room layouts\n",
        "    2. **Upload**: Upload an image (PNG/JPG)\n",
        "    3. **Generate**: Click button and wait ~10-15 seconds\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            input_image = gr.ImageEditor(\n",
        "                label=\"Draw or Upload Segmentation Mask\",\n",
        "                type=\"pil\",\n",
        "                brush=gr.Brush(\n",
        "                    colors=[\n",
        "                        \"#9AFF00\",  # Living Room (Lime)\n",
        "                        \"#FE9A00\",  # Bedroom (Orange)\n",
        "                        \"#9AFF00\",  # Kitchen (Lime - same as Living Room)\n",
        "                        \"#009BFF\",  # Bathroom (Cyan)\n",
        "                        \"#635047\",  # Closet (Brown)\n",
        "                        \"#31639B\",  # Corridor (Dark Blue)\n",
        "                        \"#000000\"   # Toilet (Black)\n",
        "                    ],\n",
        "                    default_size=30\n",
        "                ),\n",
        "                height=512\n",
        "            )\n",
        "\n",
        "            prompt = gr.Textbox(\n",
        "                label=\"Prompt\",\n",
        "                value=\"a clean architectural floorplan with walls and rooms\"\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                steps = gr.Slider(10, 50, 20, step=1, label=\"Steps\")\n",
        "                scale = gr.Slider(0.5, 2.0, 1.0, step=0.1, label=\"Scale\")\n",
        "\n",
        "            seed = gr.Slider(0, 999999, 42, step=1, label=\"Seed\")\n",
        "            generate_btn = gr.Button(\"üöÄ Generate Floorplan\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_image = gr.Image(label=\"Generated Floorplan\", type=\"pil\")\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ### üé® Color Legend:\n",
        "\n",
        "\n",
        "    ### Tips:\n",
        "    - Draw clear rectangular regions\n",
        "    - Use larger brush for bigger rooms\n",
        "    - Try different seeds for variations\n",
        "    - Higher scale = stricter layout adherence\n",
        "    \"\"\")\n",
        "\n",
        "    generate_btn.click(\n",
        "        fn=gradio_generate,\n",
        "        inputs=[input_image, prompt, steps, scale, seed],\n",
        "        outputs=output_image\n",
        "    )\n",
        "\n",
        "# Launch!\n",
        "demo.launch(share=True, debug=True)\n",
        "\n",
        "print(\"\\nInterface launched!\")\n",
        "print(\"Use the public URL to test on your phone or share with others\")\n",
        "print(\"Upload images OR draw directly on the canvas\")\n",
        "print(\"Right-click generated images to save them\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9U8XQxuFogi"
      },
      "source": [
        "##  Step 9: Save Results for Report (Optional)\n",
        "\n",
        "Generate a comprehensive comparison grid for your AI54 report Section 5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkdUQj4kFogi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\"Generating report-ready comparison grid...\\n\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "\n",
        "# Row 1: Different seeds\n",
        "print(\"Generating seed variations...\")\n",
        "seeds = [42, 123, 456, 789]\n",
        "for i, seed in enumerate(seeds):\n",
        "    if i == 0:\n",
        "        axes[0, i].imshow(layout3)\n",
        "        axes[0, i].set_title(\"Input\", fontsize=11, fontweight='bold')\n",
        "    else:\n",
        "        generated = generate_floorplan(\n",
        "            segmentation_mask=layout3,\n",
        "            seed=seed,\n",
        "            show_comparison=False\n",
        "        )\n",
        "        axes[0, i].imshow(generated)\n",
        "        axes[0, i].set_title(f\"Seed={seed}\", fontsize=11, fontweight='bold')\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "# Row 2: Different conditioning scales\n",
        "print(\"Generating scale variations...\")\n",
        "scales = [0.5, 1.0, 1.5, 2.0]\n",
        "for i, scale in enumerate(scales):\n",
        "    generated = generate_floorplan(\n",
        "        segmentation_mask=layout3,\n",
        "        controlnet_conditioning_scale=scale,\n",
        "        seed=42,\n",
        "        show_comparison=False\n",
        "    )\n",
        "    axes[1, i].imshow(generated)\n",
        "    axes[1, i].set_title(f\"Scale={scale}\", fontsize=11, fontweight='bold')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.suptitle(\"Model Testing: Seed Variations & Conditioning Scale Exploration\",\n",
        "             fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save\n",
        "output_path = \"ai54_section_5_2_comparison_grid.png\"\n",
        "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n‚úÖ Saved to: {output_path}\")\n",
        "print(\"üìÑ Use this image in your report Section 5.2!\")\n",
        "print(\"üíæ Download it from Colab Files panel (left sidebar)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1gsM3Y9Fogj"
      },
      "source": [
        "---\n",
        "\n",
        "## üéâ Testing Complete!\n",
        "\n",
        "### What You've Done:\n",
        "1. ‚úÖ Tested model on dataset samples (overfitting check)\n",
        "2. ‚úÖ Created and tested custom layouts\n",
        "3. ‚úÖ Checked output diversity with different seeds\n",
        "4. ‚úÖ Explored conditioning scale effects\n",
        "5. ‚úÖ Launched interactive drawing interface\n",
        "6. ‚úÖ Generated comparison grid for report\n",
        "\n",
        "### Next Steps:\n",
        "- **Keep the Gradio interface running** to test more layouts\n",
        "- **Download generated images** for your report\n",
        "- **Document findings** in Section 5.2\n",
        "- **Deploy to HuggingFace Spaces** when satisfied!\n",
        "\n",
        "### For Your Report (Section 5.2):\n",
        "Include:\n",
        "- Comparison grid from Step 9\n",
        "- Example inputs and outputs\n",
        "- Discussion of layout preservation\n",
        "- Any limitations observed\n",
        "\n",
        "---\n",
        "\n",
        "**Model Repository:** [Qistinasofea/controlnet-floorplan](https://huggingface.co/Qistinasofea/controlnet-floorplan)  \n",
        "**Dataset:** [Qistinasofea/floorplan-12k-aligned](https://huggingface.co/datasets/Qistinasofea/floorplan-12k-aligned)  \n",
        "**Training:** 10,000 steps, loss 0.0887, 3h42m on T4 GPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wKVjYDPPOC0g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}